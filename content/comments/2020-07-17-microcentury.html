<!-- date: 2020-07-18 10:59:51 +0000 -->
<!-- name: Ivo -->
<p>
  If we consider optimal attention span, a microcentury is much two
  long. Two half microcenturies with a pause in between would be
  better.
</p>
<!-- date: 2020-07-18 19:07:59 +0000 -->
<!-- name: Hillel Wayne -->
<!-- url: https://twitter.com/Hillelogram -->
<!-- source: https://lobste.rs/s/rsj1ov/microcentury#c_0k421w -->
<p>
  I like this analysis a lot! But there's one more twist to the story: are
  we even using the right definition of year? There's actually several
  different ways we can define a year:
</p>
<ul>
  <li>
    NIST-811 defines the light-year "year" as 365.2500 days and the
    "common year" as 365 days exactly.
  </li>
  <li>
    The sidereal year: the time it takes for the stars to return to a
    fixed point. That's 365.2563 days.
  </li>
  <li>
    The tropical year: the time between vernal equinoxes. That's 365.2421
    days.
  </li>
  <li>
    The anomalistic year: the time between points where the earth is
    closest to the sun. That's 365.2596 days.
  </li>
</ul>
<p>
  For each of these we can define the microcentury as a hundred
  microyears. So the sidereal microcentury is +35.81 seconds, while the
  tropical microcentury is +35.69 seconds. The NIST microcentury is +33.6
  seconds, while the Julian microcentury is +35.76 seconds (as you
  calculated).
</p>
<p>
  Personally, I'd define a calendar microcentury as a four-millionth of
  400 years to match the leap year cycle. That'd give us +35.692 seconds.
</p>
<!-- date: 2020-11-20 07:26:37 +0000 -->
<!-- name: Fran&ccedil;ois Best -->
<!-- url: https://francoisbest.com -->
<p>
  We had a running joke in engineering school, that &pi; seconds is
  close to a nanocentury by around 6 nanomonths, we obviously didn't
  go that far in calculations, so I wonder if it still holds.
</p>
