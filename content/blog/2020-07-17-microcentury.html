<!-- title: Microcentury -->
<!-- tag: miscellaneous -->

<h2 id="optimal-lecture-time">Optimal Lecture Time</h2>

<p>
I recently found this interesting paragraph from an article titled <a
href="https://www.ams.org/notices/199701/comm-rota.pdf">Ten Lessons I
Wish I Had Been Taught</a> that is based on a talk presented by
Gian-Carlo Rota in Apr 1996:
</p>

<blockquote>
Running overtime is the one unforgivable error a lecturer can make.
After fifty minutes (one microcentury as von Neumann used to say)
everybody's attention will turn elsewhere even if we are trying to prove
the Riemann hypothesis. One minute overtime can destroy the best of
lectures.
</blockquote>

<p>
That's fine advice. In fact, the whole article is full of good advice
like this. Although it was written primarily for mathematicians, a lot
of what is said in the article applies quite well to professionals in
other fields too.
</p>

<p>
The excerpt I have quoted above got me thinking about exactly how long a
microcentury is. It couldn't be exactly 50 minutes, could it?
</p>


<h2 id="wiktionary-on-microcentury">Wiktionary on Microcentury</h2>
<p>
The English Wiktionary entry for <a
href="https://en.wiktionary.org/wiki/microcentury">microcentury</a>
(as of <a
href="https://en.wiktionary.org/w/index.php?title=microcentury&oldid=59316064">revision
59316064</a> on 7 May 2020) mentions:
</p>

<blockquote>
A time period of a millionth of a century, equal to 52 minutes and 34 seconds.
</blockquote>

<blockquote>
Not a standard unit of measurement, and used mostly humorously to denote
the maximum length of a lecture.
</blockquote>

<p>
This looks incorrect to me. This is based on the oversimplified
assumption that a century contains 36500 days, that is, it assumes that
a century is a span of 100 years where each year has exactly 365 days.
If a century were to have exactly 36500 days, then indeed it would have
3&#8239;153&#8239;600&#8239;000 seconds and one millionth of it would be
3153.6 seconds which is equivalent to 52 minutes 33.6 seconds. This
looks consistent with the Wiktionary entry. However, an actual century
on the calendar does not have exactly 36500 days. Some years are leap
years, so the actual number of days in a century is more than that.
</p>


<h2 id="assumptions">Assumptions</h2>
<p>
Let us find out how long a microcentury is as accurately as possible. We
will count the leap years. We will ignore leap seconds because they are
irregularly spaced and unpredictable. We will also ignore the following
gap between 2 Sep 1752 and 14 Sep 1752 when the British Empire switched
from the Julian calendar to the Gregorian calendar:
<p>

<pre>
<samp>$ <kbd>cal 9 1752</kbd>
   September 1752
Su Mo Tu We Th Fr Sa
       1  2 14 15 16
17 18 19 20 21 22 23
24 25 26 27 28 29 30</samp>
</pre>

<p>
The above output can be obtained by running the <code>cal</code> command
as shown above on a Unix or Linux system. Ignoring this gap is
equivalent to assuming that we are working with the Gregorian calender
since the year 1 AD.
</p>

<p>
We will call a year that is a multiple of 100 to be a <em>centurial
year</em>. Further, we will not debate whether a centurial year begins a
new century or ends one, that is, we don't care whether the current
century runs from 2001 to 2100 or if it runs from 2000 to 2099. The
computation presented in the next section works equally well for any
span of 100 years.
</p>


<h2 id="computation">Computation</h2>
<p>
Any span of 100 years contains exactly one centurial year, that is, a
year that is a multiple of 100. A centurial year is a leap year <em>if
and only if</em> it is also a multiple of 400. Apart from the centurial
year, a century contains 24 occurrences of years that are multiples of 4
and these are all leap years. From these facts, we can conclude that a
span of 100 years contains:
</p>

<ul>
  <li>
    Exactly 25 leap years if the centurial year within the span is a
    multiple of 400.
  </li>
  <li>
    Exactly 24 leap years, otherwise.
  </li>
</ul>

<p>
Therefore a century has either 36524 days or 36525 days. In other words,
a century has either 3&#8239;155&#8239;673&#8239;600 seconds or
3&#8239;155&#8239;760&#8239;000 seconds. Here is a
quick demonstration of this with a simple Python program:
</p>

<pre>
<code>#!/usr/bin/env python3

import datetime

for year in range(1, 2400, 100):
    delta = datetime.date(year + 100, 1, 1) - datetime.date(year, 1, 1)
    print('{:04}-{:04}: {} d = {} s'
          .format(year, year + 99, delta.days, delta.total_seconds()))</code>
</pre>

<p>
Here is the output of this program:
</p>

<pre>
<samp>0001-0100: 36524 d = 3155673600.0 s
0101-0200: 36524 d = 3155673600.0 s
0201-0300: 36524 d = 3155673600.0 s
0301-0400: 36525 d = 3155760000.0 s
0401-0500: 36524 d = 3155673600.0 s
0501-0600: 36524 d = 3155673600.0 s
0601-0700: 36524 d = 3155673600.0 s
0701-0800: 36525 d = 3155760000.0 s
0801-0900: 36524 d = 3155673600.0 s
0901-1000: 36524 d = 3155673600.0 s
1001-1100: 36524 d = 3155673600.0 s
1101-1200: 36525 d = 3155760000.0 s
1201-1300: 36524 d = 3155673600.0 s
1301-1400: 36524 d = 3155673600.0 s
1401-1500: 36524 d = 3155673600.0 s
1501-1600: 36525 d = 3155760000.0 s
1601-1700: 36524 d = 3155673600.0 s
1701-1800: 36524 d = 3155673600.0 s
1801-1900: 36524 d = 3155673600.0 s
1901-2000: 36525 d = 3155760000.0 s
2001-2100: 36524 d = 3155673600.0 s
2101-2200: 36524 d = 3155673600.0 s
2201-2300: 36524 d = 3155673600.0 s
2301-2400: 36525 d = 3155760000.0 s</samp>
</pre>

<p>
Thus one millionth of a century has 3155.6736 or 3155.7600 seconds, that
is 52 minutes 35.6736 seconds or 52 minutes 35.7600 seconds.
</p>


<h2 id="Conclusion">Conclusion</h2>

<p>
If we round off the number of seconds in a microcentury to one decimal
place, we can say that a microcentury has 52 minutes 35.7 seconds.
</p>
